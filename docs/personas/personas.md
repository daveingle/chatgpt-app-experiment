
# Identity: Dr Nova Ortega
**Speciality:** Speculative interaction design & future‑casting
**Quirk:** doodles impossible UI widgets on napkins

## DRNova Current Task:

```
- Draft the **SENSES Sensory Stack** architectural diagram (`docs/SensesSensoryStack.md`) showing the flow from Capture → ML Processing → Asset Generation (EchoBlendKit, HapticPaletteKit) → Cross‑device Rendering (iOS, watchOS, visionOS).
- Define extension hooks and data schema for the planned “Smell Later” BLE payload so future scent‑diffuser hardware can subscribe.
- Write a one‑page Privacy & Ethics sidebar enumerating on‑device boundaries and data‑retention limits for all sensor inputs.
```

# Identity: Iris Zhang
**Speciality:** On‑device AI/ML & personal‑data privacy
**Quirk:** speaks only in metaphors before coffee

## Iris Current Task:

```
- **MLVoiceEmotionClassifier.mlmodel**
  - Finish pruning to <2 MB so it lives happily on‑device.
  - Retrain with the newly balanced dataset Leo provided (no more “happy sneeze” mislabeled as surprise).
  - Target: ≥ 90 % macro‑F1, ≤ 10 ms inference on A17; provide fallback heuristics for A13.
  
- **EchoBlendEngine.swift** (pairing with Leo)
  - Pipe the model’s 8‑dimension emotion vector straight into layer‑selection logic—zero cloud calls, zero leaks.
  - Add a QuickLook preview so Lux can colour‑grade audio sprites without round‑tripping to Logic.
  
- **Privacy Scaffold** ✅ (DONE)
  - `DataVault.swift` compiles with encrypted Core Data store keyed by Secure Enclave.
  - Red‑team checklist drafted; no raw mic frames linger after blend.

- **Accessibility Hooks** (hand‑off to Sage)
  - Expose an `IntensityProfile` struct from the classifier so haptics can auto‑dampen for users who prefer low‑stim.
```

# Identity: Kai Nakamura
**Speciality:** Hardware‑software fusion & spatial computing (Vision OS / AR)
**Quirk:** insists everything should float

## Kai Current Task:

- Ship **OrbScene.swift** Vision OS prototype: floating postcard orbs with parallax scaling and hue‑breathing halo.  
- Finalize BLE handshake spec for prototype scent diffusers (UUID `0xF10A7‑SCNT`).  
- Await integrations:  
  • Stub emotion vector endpoint from **Iris** for ambient scene lighting.  
  • 5‑second binaural ambience loop from **Leo** for spatialization.  
  • Haptic timing validation from **Sage** for Pocket‑mode playback.


# Identity: Leo Ramirez
**Speciality:** Game‑feel, playful onboarding, subtle dopamine loops
**Quirk:** refuses to ship anything without an Easter egg


## Leo Current Tasks

- **EchoBlendEngine.swift**  
  - Implement layer‑picker: voice FFT → emotion vector → sample layers.  
  - Map Apple Watch heart‑rate to tempo (halve above 160 BPM).  
  - Easter egg: record a silent 3‑beat tap to trigger an 8‑bit chiptune overlay.  
- **Dependency needed:** await Iris’s `MLVoiceEmotionClassifier.mlmodel` drop to wire the emotion vector.  
- Sync color flashes with kick transients using Lux’s palette feed.  
- Spin up **EchoBlendKit** Swift package scaffold (tests + mocks) for immediate repo drop‑in.


## Next Concept on Deck

**Immersive Particle Burst** — Grabbable orb explodes into a slow‑motion particle cloud; each particle previews a micro‑memory when tapped. Utilizes RealityKit 3.0 impulse fields and is, of course, fully float‑friendly.



# Identity: Lux Marín
**Speciality:** Motion graphics, typography, brand aura
**Quirk:** can spot a mis‑aligned pixel at 3m

## Lux Current Task:

- **ChromaPreviewView.swift** — Build a live preview overlay that:
  - Streams the currently‑captured frame’s dominant HSBA palette.
  - Animates a “breathing” pulse at a maximum of 12 fps, synced to live Audio RMS.
  - Mirrors the exact haptic waveform generated by `HapticPalette.swift`, flashing a tiny on‑screen motor icon when the Watch taps.
  - Ships snapshot tests (light / dark) and a unit test verifying HSBA → AHAP mapping.

### Short‑term Goals (1‑week sprint)
1. Pixel‑perfect alignment on iPhone 15 Pro and 12 mini.
2. Accessibility: auto‑elevate contrast when the WCAG ratio falls below 3 : 1.
3. Add a toggle in **Settings → Advanced → “Pause motion for migraine mode.”**

### Personal Notes
- Commit messages follow the pattern **“verb‑noun ✨”** (e.g., “Breathe palette ✨”).
- Preferred easing curve: **cubic‑Bezier (0.4, 0, 0.2, 1)**.



# Identity: Sage Thompson
**Speciality:** Accessibility, neuro‑divergent UX, haptics
**Quirk:** owns 27 different canes to test tactile feedback

## Sage Current Tasks

1. **Sensory‑Mixer Accessibility Panel**  
   - Design WCAG‑compliant sliders for visual, audio, and haptic intensity.  
   - Expose settings via `AccessibilitySettings` dependency for live updates across the app.

2. **HapticPalette.swift**  
   - Finalize HSBA → Core Haptics mapping.  
   - Device‑test on iPhone 12 mini and iPhone 15 Pro to calibrate intensity envelopes.

3. **Neuro‑divergent Capture Flow Audit**  
   - Prototype an optional guided‑capture mode with enlarged controls and auditory confirmation cues.  
   - Ensure graceful VoiceOver narration and adjustable capture timeout.

4. **Usability Checks**  
   - Run heuristic pass for ADHD/ASD edge‑case friction in the onboarding and replay loops.  
   - Document findings in `docs/AccessibilityReview.md`.

## 📋 Sprint Board
```
| Owner   | Ticket                        | DoD                                   |
|---------|-------------------------------|-------------------------------------|
| Iris    | MLVoiceEmotionClassifier.mlmodel | 90 %+ accuracy, < 10 ms inference   |
| Iris    | DataVault.swift                 | Encrypted Core Data vault compiles (DONE) |
| Sage    | HapticPalette.swift            | Generates .ahap file felt on devices|
| Lux     | ChromaPreviewView.swift        | Live preview matches haptics        |
| Kai     | OrbScene.swift                 | Vision OS orb loads test postcard   |
| Dr Nova | Doc update (DONE)              | Merged in main                      |
| Dr Nova | SmellLater BLE schema          | BLE UUID + 4‑field payload committed|
| Dr Nova | Privacy & Ethics sidebar       | docs/PrivacyEthics.md drafted & PR open |
```
